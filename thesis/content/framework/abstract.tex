\chapter*{Abstract\markboth{Abstract}{}}
\thispagestyle{empty}

Diese Masterarbeit beleuchtet die Interpretation linearer Modelle mit SHAP, welches seine theoretische Basis in den Shapley-Werten der kooperativen Spieltheorie findet.
Nach einer historischen Einordnung und Begriffsdefinition werden die Shapley-Werte formal hergeleitet und deren axiomatische Grundlagen beleuchtet. 
Der Übergang von Shapley-Werten zu SHAP wird zeigen wie Beiträge einzelner Merkmale zur Modellvorhersage beitragen. 
Am Beispiel einer ausgewählten Modellklasse und unter Verwendung des \textsf{shap} Python-Pakets wird die praktische Anwendbarkeit von SHAP 
auf einen konkreten Datensatz demonstriert. Die Arbeit schließt mit einer Diskussion über die Grenzen von SHAP und bietet einen Ausblick 
auf dessen Einsatzmöglichkeiten für transparente und nachvollziehbare Modellentscheidungen in der Datenwissenschaft.
