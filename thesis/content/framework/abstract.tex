\chapter*{Abstract\markboth{Abstract}{}}
\thispagestyle{empty}

In dieser Masterarbeit wird die Interpretation von linearen Modellen unter Verwendung von SHAP untersucht, 
einem Ansatz, der auf den Shapley-Werten der kooperativen Spieltheorie basiert. 
Die Arbeit beginnt mit einer historischen Kontextualisierung und Definition der relevanten Begriffe, 
gefolgt von einer formalen Ableitung der Shapley-Werte und einer Untersuchung ihrer axiomatischen Prinzipien. 
Es wird dargelegt, wie SHAP aus Shapley-Werten entwickelt wurde, um den Beitrag einzelner Merkmale zur Modellprognose 
zu verdeutlichen. Anhand eines spezifischen Modelltyps und unter Einsatz des Python-Pakets 
\textsf{shap} wird die praktische Umsetzbarkeit von SHAP auf einen realen Datensatz demonstriert. 
Die Arbeit endet mit einer kritischen Diskussion über die Limitierungen von SHAP und gibt einen Ausblick 
auf dessen potenziellen Einsatz für transparente und nachvollziehbare Entscheidungsfindungen in der Datenwissenschaft.
