\chapter{Einleitung}

In einer Ära, in der datengetriebene Entscheidungsfindung und automatisierte Modelle zunehmend an Bedeutung gewinnen,
wird die Fähigkeit der Erklärung und Interpretation dieser Modelle immer wichtiger. Denn während maschinelles Lernen und
künstliche Intelligenz beeindruckende Fortschritte gemacht haben, bleiben viele Modelle aufgrund ihrer Komplexität und Undurchsichtigkeit
schwer verständlich. Die Frage, warum ein bestimmtes Modell eine bestimmte Entscheidung getroffen hat oder wie sich die einzelnen
Merkmale auf die Vorhersagen auswirken, wird zu einem zentralen Anliegen. 
Shapley-Werte bieten eine Möglichkeit, die \glqq{}Black Box\grqq{} der Modelle zu öffnen und Einblicke 
in die zugrunde liegenden Mechanismen zu gewinnen \cite[S. 3]{Molnar_2023}. 

Diese Masterarbeit widmet sich einer tiefgehenden Untersuchung der Shapley-Werte und erforscht ihr Potenzial für die Interpretation
von Machine Learning-Modellen, insbesondere linearer Modelle, sowie ihre Anwendbarkeit auf reale Datensätze.

Die Arbeit beginnt mit einer Einführung in die Shapley-Werte, indem ihre historischen Ursprünge 
und ihre Verbindung zur kooperativen Spieltheorie beleuchtet werden. Die theoretischen Grundlagen dieser Werte werden 
ergründet und ihre Bedeutung für die Interpretation von Modellen untersucht.

Anschließend wird der Fokus auf die Anpassung und Erweiterung der Shapley-Werte für maschinelles Lernen gelegt. 
Hierbei wird untersucht, wie Shapley-Werte modifiziert werden können, um tiefere Einsichten in die Gewichtung 
und Bedeutung einzelner Merkmale innerhalb komplexer Machine Learning-Modelle zu liefern. Dabei wird ein Vergleich 
mit bestehenden Methoden, wie der Permutation der Merkmalrelevanz, gezogen, um die Einzigartigkeit und den Mehrwert der 
Shapley-Werte hervorzuheben.

Durch die Analyse eines realen Datensatzes wird die Methodik in der Praxis angewendet. Die Fallstudie zur Vorhersage der 
Druckfestigkeit von Beton bietet dabei ein konkretes Beispiel, anhand dessen die Nuancen und die Tiefe der durch SHAP 
ermöglichten Analysen veranschaulicht werden.

Abschließend werden die gewonnenen Erkenntnisse zusammengefasst und reflektiert. Es wird speziell die Rolle und das 
Potenzial der Shapley-Werte in diesem Kontext beleuchtet. Dabei werden auch die Grenzen und Herausforderungen, 
die mit der Anwendung von Shapley-Werten verbunden sind, kritisch diskutiert. 