\chapter{Einleitung}

In einer Ära, in der datengetriebene Entscheidungsfindung und automatisierte Modelle zunehmend an Bedeutung gewinnen,
wird die Fähigkeit der Erklärung und Interpretation dieser Modelle immer wichtiger. Denn während maschinelles Lernen und
künstliche Intelligenz beeindruckende Fortschritte gemacht haben, bleiben viele Modelle aufgrund ihrer Komplexität und Undurchsichtigkeit
schwer verständlich. Die Frage, warum ein bestimmtes Modell eine bestimmte Entscheidung getroffen hat oder wie sich die einzelnen
Merkmale auf die Vorhersagen auswirken, wird zu einem zentralen Anliegen. 
Hier kommen die Shapley-Werte ins Spiel, ein Konzept
aus der kooperativen Spieltheorie, das in der Welt des maschinellen Lernens immer mehr an Bedeutung gewinnt. Sie bieten eine
Möglichkeit, die \glqq{}Black Box\grqq{} der Modelle zu öffnen und Einblicke in die zugrunde liegenden Mechanismen zu gewinnen \cite[S. 3]{Molnar_2023}. 

Diese Masterarbeit widmet sich einer tiefgehenden Untersuchung der Shapley-Werte und erforscht ihr Potenzial für die Interpretation
von Machine Learning-Modellen, insbesondere linearer Modelle, sowie ihre Anwendbarkeit auf reale Datensätze.

Die Arbeit beginnt mit einer ausführlichen Einführung in die Shapley-Werte, indem ihre historischen Ursprünge 
und ihre Verbindung zur kooperativen Spieltheorie beleuchtet werden. Durch die Analyse relevanter Literatur 
werden die theoretischen Grundlagen dieser Werte ergründet und ihre Bedeutung für die Interpretation von Modellen untersucht.

Anschließend wird der Fokus auf die Anpassung und Erweiterung der Shapley-Werte für maschinelles Lernen gelegt. 
Hierbei wird untersucht, wie Shapley-Werte modifiziert werden können, um tiefere Einsichten in die Gewichtung 
und Bedeutung einzelner Merkmale innerhalb komplexer Machine Learning-Modelle zu liefern. Dabei wird ein Vergleich 
mit bestehenden Methoden, wie der Permutation der Merkmalrelevanz, gezogen, um die Einzigartigkeit und den Mehrwert der 
Shapley-Werte hervorzuheben.

Ein wesentlicher Teil der Arbeit widmet sich der praktischen Anwendung der Shapley-Werte. Durch die Analyse 
eines realen Datensatzes wird die Methodik in der Praxis angewendet. Dies dient nicht nur dazu, die Wirksamkeit 
der Shapley-Werte zu demonstrieren, sondern auch, um ihre Aussagekraft und Anwendungsgrenzen in realen Szenarien 
zu evaluieren. Die Fallstudie zur Vorhersage der Druckfestigkeit von Beton bietet dabei ein konkretes Beispiel, 
anhand dessen die Nuancen und die Tiefe der durch SHAP ermöglichten Analysen veranschaulicht werden.

Abschließend werden die gewonnenen Erkenntnisse zusammengefasst und reflektiert. Es wird speziell die Rolle und das 
Potenzial der Shapley-Werte in diesem Kontext beleuchtet. Dabei werden auch die Grenzen und Herausforderungen, 
die mit der Anwendung von Shapley-Werten verbunden sind, kritisch diskutiert. 