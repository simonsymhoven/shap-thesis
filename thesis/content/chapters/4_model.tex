\chapter{Praktische Anwendung von SHAP auf lineare Modelle}

In diesem Kapitel wird der Einsatz des SHAP-Frameworks zur Interpretation linearer Modelle im 
Kontext des maschinellen Lernens untersucht. Lineare Modelle, gekennzeichnet durch ihre Transparenz 
und einfache Struktur, bilden oft die Basis für das Verständnis komplexerer Algorithmen. 
Dennoch bleibt die Herausforderung bestehen, die Beiträge individueller Merkmale zur Modellvorhersage zu 
quantifizieren und zu interpretieren.

Die Anwendung von SHAP-Werten ermöglicht es, diesen Herausforderungen zu begegnen und Einblicke in 
die Modellvorhersagen zu gewähren, die über traditionelle Methoden hinausgehen. 
Dieses Kapitel führt in die Grundlagen des \textsf{shap}-Pakets ein, demonstriert dessen Anwendung auf einen 
spezifischen Datensatz und diskutiert die Berechnung sowie Interpretation der resultierenden SHAP-Werte. 
Die daraus gewonnenen Erkenntnisse leisten einen Beitrag zur Erklärbarkeit von Vorhersagemodellen und 
unterstützen somit die wissenschaftliche Diskussion um die Verantwortlichkeit und Nachvollziehbarkeit 
in der maschinellen Lernforschung.

\section{Lineare Modelle als analytische Grundlage}

In linearen Regressionsmodellen wird die Zielgröße als eine gewichtete Kombination der Eingangsmerkmale bestimmt. 
Die einfache lineare Struktur dieser Modelle erleichtert das Verständnis der Beziehungen zwischen den Eingangsdaten 
und den Vorhersagen. 

Lineare Modelle sind ein grundlegendes Werkzeug in der statistischen Modellierung und dienen dazu, das Verhältnis zwischen 
einer abhängigen Variablen, die üblicherweise mit $y^{(i)}$ bezeichnet wird, 
und einem oder mehreren Prädiktoren, den unabhängigen Variablen $x_i$, zu erfassen. 
Diese Beziehungen werden mittels linearer Gleichungen dargestellt, die für jede 
einzelne Beobachtung $i$ im Datensatz folgendermaßen formuliert werden können:

\begin{equation}
    y^{(i)} = \beta_0 + \sum_{j=1}^{p} \beta_j x^{(i)}_j + \epsilon^{(i)},
\end{equation}

wobei das Ergebnis, das von einem linearen Modell für eine gegebene Beobachtung vorhergesagt wird, sich als Summe der mit 
Gewichten $\beta_j$ versehenen Merkmale $p$ ergibt.

Hierbei stellt $y^{(i)}$ den beobachteten Wert der abhängigen Variablen für die Beobachtungseinheit
$i$ dar. Der Term $\beta_0$ ist der Achsenabschnitt oder y-Achsenabschnitt des Modells, 
welcher den erwarteten Wert von $y$ darstellt, wenn alle unabhängigen Variablen $x$ null sind. 
Die Summe $\sum_{j=1}^{p} \beta_j x^{(i)}_j$ berechnet sich aus den Produkten der Koeffizienten 
$\beta_j$ und den Werten der unabhängigen Variablen $x^{(i)}_j$ für jede Beobachtungseinheit $i$ 
und jeden Prädiktor $j$, wobei die Koeffizienten $\beta_j$ den geschätzten Einfluss der 
entsprechenden unabhängigen Variablen auf die abhängige Variable beschreiben.

Der Fehlerterm $\epsilon^{(i)}$ steht für die Residuen, also die Differenzen zwischen den beobachteten 
und durch das Modell geschätzten Werten von $y^{(i)}$. Es wird angenommen, dass diese Fehler normalverteilt sind, 
was bedeutet, dass Abweichungen in beiden Richtungen um den Mittelwert (hier Null) 
mit abnehmender Wahrscheinlichkeit für größere Fehler auftreten \cite[S. 37]{Molnar_2022}.

In einem linearen Modell stellt der Achsenabschnitt die Basislinie dar, an der die Auswirkungen aller 
anderen Merkmale gemessen werden. Dieser Wert gibt an, was das Modell für die Zielvariable vorhersagen 
würde, wenn alle anderen Merkmale nicht vorhanden wären – der Ausgangspunkt der Vorhersage 
für einen Datensatz, in dem alle anderen Variablen auf null gesetzt sind. 
Es ist wichtig zu erwähnen, dass der Achsenabschnitt für sich genommen nicht immer eine praktische 
Bedeutung hat, da es selten vorkommt, dass alle Variablen tatsächlich den Wert null annehmen. 
Die wahre Aussagekraft des Achsenabschnitts tritt zutage, wenn die Daten so standardisiert wurden, 
dass ihre Mittelwerte bei null und die Standardabweichung bei eins liegen. Unter diesen Umständen repräsentiert der Achsenabschnitt 
die erwartete Zielvariable für einen hypothetischen Fall, in dem alle Merkmale ihren Durchschnittswert 
aufweisen.

Bei der Betrachtung einzelner Merkmale innerhalb des Modells sagt das Gewicht $\beta_j$ eines Merkmals, 
um wie viel sich die Zielvariable $y^{(i)}$ ändert, wenn das Merkmal $x^{(i)}_j$ um eine Einheit erhöht wird – und zwar unter 
der Annahme, dass alle anderen Merkmale unverändert bleiben. 
Dies ermöglicht es, den isolierten Effekt eines jeden Merkmals auf die Vorhersage zu verstehen \cite[S. 39]{Molnar_2022}.

Die optimalen Gewichte, oder Koeffizienten, eines linearen Regressionsmodells werden üblicherweise durch ein Verfahren bestimmt, 
das als Methode der kleinsten Quadrate (engl. \textit{Ordinary Least Squares}, OLS) bekannt ist. 
Diese Methode sucht die Koeffizienten \( \beta_0, \ldots, \beta_p \), welche die Summe der quadrierten 
Differenzen zwischen den beobachteten Werten der Zielvariablen \( y^{(i)} \) und den von dem Modell 
vorhergesagten Werten minimieren:

\begin{equation}
    \hat{\beta} = \arg \underset{\beta_0, \ldots, \beta_p}{\min} \ \sum_{i=1}^{n} \left( y^{(i)} - \left( \beta_0 + \sum_{j=1}^{p} \beta_j x_j^{(i)}\right)\right)^2.
\end{equation}

Das Ergebnis der Minimierung, \( \hat{\beta} \) stellt den Vektor der geschätzten Koeffizienten dar \cite[S. 37]{Molnar_2022}. 
In der vorliegenden Arbeit wird das Python-Paket \textsf{scikit-learn}\footnote{\url{https://scikit-learn.org}} verwendet, um die lineare Regression durchzuführen und die Koeffizienten 
\( \hat{\beta} \) zu bestimmen. 


\section{Einführung in das \textsf{shap} Python-Paket}

Das Python-Paket \textsf{shap}\footnote{\url{https://shap.readthedocs.io}} ist eine Open-Source-Bibliothek, die es Nutzern ermöglicht, 
die Auswirkungen von Merkmalen auf Vorhersagen von maschinellen Lernmodellen zu interpretieren und zu visualisieren. 
Entwickelt wurde die Bibliothek ursprünglich von Scott Lundberg und weiteren Mitwirkenden im Rahmen der Forschungsarbeit 
an der University of Washington \cite{NIPS2017_8a20a862}. Das Paket basiert auf dem Konzept der Shapley-Werte aus der kooperativen Spieltheorie 
und überträgt diese auf den Kontext des maschinellen Lernens, um als Tool für die Interpretierbarkeit und Erklärbarkeit 
von Modellvorhersagen zu dienen.

Die Kernfunktion des \textsf{shap}-Pakets ist die Berechnung von SHAP-Werten, welche die Auswirkung der 
Einzelmerkmale auf die Modellvorhersage quantifizieren. Jeder SHAP-Wert ist ein Maß dafür, wie viel jedes Merkmal 
zur Vorhersage beigetragen hat, im Vergleich zu einer durchschnittlichen Vorhersage über den gesamten Datensatz. 
Diese Werte sind besonders wertvoll, weil sie ein Maß für die Bedeutung jedes Merkmals liefern, 
das sowohl lokal (für einzelne Vorhersagen) als auch global (über das gesamte Modell) interpretiert werden kann.

Mit \textsf{shap} können Benutzer die Vorhersagen einer Vielzahl von Modellen interpretieren, 
von linearen Modellen bis hin zu komplexen Konstrukten wie tiefe neuronale Netzwerke. 
Die Bibliothek bietet eine vielseitige Auswahl an Visualisierungsoptionen, darunter Beeswarm-Plots, Dependence-Plots und 
Summary-Plots, die es ermöglichen, die SHAP-Werte intuitiv zu verstehen.
Diese Visualisierungen erleichtern es, Muster und Beiträge einzelner Merkmale zu erkennen, 
was nicht nur wertvolle Einblicke in die Leistung des Modells bietet, sondern auch zu faireren und transparenteren 
Modellentscheidungen führen kann. 

\section{Einführung in den Datensatz}

Der für diese Studie verwendete Datensatz umfasst 244 Beobachtungen, die Daten aus zwei Regionen Algeriens zusammenfassen: 
der Bejaia-Region im Nordosten und der Sidi Bel-Abbes-Region im Nordwesten des Landes. 
Für jede Region wurden Daten aus dem Zeitraum von Juni bis September 2012 erfasst, 
wobei jede Region mit 122 Instanzen repräsentiert ist.

Der Datensatz beinhaltet 11 Merkmale, die verschiedene Aspekte der Wetterbedingungen und 
des Fire Weather Index (FWI) Systems beschreiben, sowie ein Zielattribut (Klasse), 
das ursprünglich die Instanzen in zwei Klassen einteilte: Feuer (138 Instanzen) und kein 
Feuer (106 Instanzen) \cite{misc_algerian_forest_fires_dataset___547}. 

Für die Zwecke dieser Analyse liegt der Fokus auf einer Regression des FWI, 
weshalb die Klassifikationsvariable aus den Daten entfernt wurde. Dadurch konzentriert sich die Untersuchung 
ausschließlich auf die Vorhersage des FWI-Wertes anstelle der Einteilung in Brand- und Nicht-Brand-Klassen.

Die Merkmale des Datensatzes umfassen:

\begin{itemize}
    \item \textbf{Datum}: Tag, Monat und Jahr der Beobachtung.
    \item \textbf{Temperatur (Temp)}: Die mittägliche Maximaltemperatur in Grad Celsius, die zwischen 22 und 42 Grad variiert.
    \item \textbf{Relative Feuchtigkeit (RH)}: Die relative Luftfeuchtigkeit in Prozent, mit Werten von 21 bis 90 Prozent.
    \item \textbf{Windgeschwindigkeit (Ws)}: Die Windgeschwindigkeit in Kilometern pro Stunde, die zwischen 6 und 29 km/h liegt.
    \item \textbf{Regen}: Die Gesamtregenmenge des Tages in Millimetern, mit Werten von 0 bis 16,8 mm.
\end{itemize}

Zusätzlich beinhaltet der Datensatz Komponenten des FWI-Systems, das als ein umfassendes System zur Einschätzung der potenziellen 
Feuergefahr dient:

\begin{itemize}
    \item \textbf{Fine Fuel Moisture Code (FFMC)}: Ein Index, der die Feuchtigkeit des Streufalls und leicht entflammbaren Materials beschreibt, mit Werten von 28,6 bis 92,5.
    \item \textbf{Duff Moisture Code (DMC)}: Ein Index, der die Feuchtigkeit des Auflagehumus und mitteltiefen Streufalls misst, mit Werten von 1,1 bis 65,9.
    \item \textbf{Drought Code (DC)}: Ein Index, der die Trockenheit des tieferen Bodens beschreibt, mit Werten von 7 bis 220,4.
    \item \textbf{Initial Spread Index (ISI)}: Ein Index, der das anfängliche Ausbreitungspotenzial eines Feuers darstellt, mit Werten von 0 bis 18,5.
    \item \textbf{Buildup Index (BUI)}: Ein Index, der die Menge an verfügbarem brennbaren Material beschreibt, mit Werten von 1,1 bis 68.
    \item \textbf{Fire Weather Index (FWI)}: Der umfassende Index, der auf den anderen Indizes basiert und das tägliche Feuerbrandrisiko angibt, mit Werten von 0 bis 31,1.
\end{itemize}

Weitere Informationen zum FWI-System und den spezifischen Indizes können im offiziellen Dokument des Canadian Forest Fire Danger 
Rating System gefunden werden \cite{Van_Wagner_1987}.

Der Datensatz wurde in Python mithilfe der Bibliothek \textsf{pandas} als DataFrame eingelesen, 
wobei die Spalten für Tag, Monat und Jahr kombiniert und als Index des DataFrames verwendet wurden. Tabelle \ref{tab:df-head}
zeigt die ersten drei Beobachtungen des Datensatzes:

\begin{table}[h]
    \caption{Auszug des Datensatzes mit Wetter- und FWI-Indizes.}
    \footnotesize
    \begin{tabularx}{\textwidth}{lrrrrrrrrrr}
    \toprule
    Datum       & Temp & RH & Ws & Rain & FFMC & DMC & DC  & ISI & BUI & FWI \\
    \midrule
    2012-06-01  & 29   & 57 & 18 & 0.0  & 65.7 & 3.4 & 7.6 & 1.3 & 3.4 & 0.5 \\
    2012-06-02  & 29   & 61 & 13 & 1.3  & 64.4 & 4.1 & 7.6 & 1.0 & 3.9 & 0.4 \\
    2012-06-03  & 26   & 82 & 22 & 13.1 & 47.1 & 2.5 & 7.1 & 0.3 & 2.7 & 0.1 \\
    \bottomrule
    \end{tabularx}
    \label{tab:df-head}
    \normalsize\\
    Quelle: Eigene Darstellung auf Basis der Datengrundlage \cite{misc_algerian_forest_fires_dataset___547}.
\end{table}

Der vollständige Quellcode für das Einlesen der Daten sowie alle weiteren Analyseschritte ist 
im Anhang \ref{linreg} dieser Arbeit zu finden.

\section{Explorative Datenanalyse}



\section{Modellierung der linearen Regression}

TODO: Modell fitten


\begin{figure}[H]
    \caption{Residuenanalyse: Beziehung zwischen Vorhersagen und Abweichungen.}
    \includegraphics[width=1\textwidth]{../scripts/images/residuals.png}
    Quelle: Eigene Darstellung, \ref{linreg}.
    \label{pic:residuals}
\end{figure}