\chapter{Fazit}

Diese Arbeit hat die Anwendung und Interpretation von SHAP-Werten in der 
linearen Regressionsanalyse zur Vorhersage der Druckfestigkeit von Beton umfassend untersucht. 
SHAP-Werte, als ein fortschrittlicher Ansatz zur Modellinterpretation, haben sich als besonders 
wertvoll erwiesen, indem sie eine tiefere und nuanciertere Einsicht in die Beiträge einzelner 
Merkmale zur Modellvorhersage bieten. Im Vergleich zu herkömmlichen Interpretationsmethoden, 
wie der Analyse der Regressionskoeffizienten und der Permutation der Merkmalrelevanz, 
bieten SHAP-Werte mehrere Vorteile.

Einer der Hauptvorteile von SHAP-Werten liegt in ihrer Fähigkeit, sowohl globale als auch 
lokale Interpretationen zu ermöglichen. Sie erlauben es, den Einfluss einzelner Merkmale auf 
spezifische Vorhersagen zu verstehen, während gleichzeitig ein Überblick über deren Bedeutung 
im gesamten Modell gegeben wird. Darüber hinaus berücksichtigen SHAP-Werte die Interaktionen 
zwischen den Merkmalen und bieten somit eine ganzheitliche Sicht auf die Modellvorhersagen. 
Dies ist besonders relevant in komplexen Datenstrukturen, wo Merkmalsinteraktionen eine signifikante
Rolle spielen.

Ein weiterer zentraler Vorteil der SHAP-Werte liegt in ihrer umfassenden Erklärungskraft.
Im Gegensatz zur Permutation der Merkmalrelevanz, die sich darauf konzentriert, wie sich der 
Vorhersagefehler des Modells verändert, wenn die Werte eines Merkmals zufällig vertauscht werden, 
bieten SHAP-Werte eine detaillierte Aufschlüsselung des Beitrags jedes einzelnen Merkmals zur 
Vorhersage. Diese Eigenschaft der SHAP-Werte ist von Vorteil, da sie eine faire 
Aufteilung der Vorhersageabweichung unter allen Merkmalsausprägungen gewährleistet – bekannt 
als die Effizienzeigenschaft der Shapley-Werte. Diese faire Aufteilung ist dann wichtig, 
wenn eine vollständige und transparente Erklärbarkeit erforderlich ist.

Trotz dieser Stärken ist es wichtig, auch die Grenzen der SHAP-Methode zu erkennen. 
Eine der Herausforderungen bei der Anwendung von SHAP-Werten ist die Interpretation der Ergebnisse, 
insbesondere wenn es um komplexe Modelle mit einer großen Anzahl von Merkmalen und komplizierten 
Interaktionen geht. Die Interpretation kann schnell überwältigend werden und erfordert ein tiefes 
Verständnis der zugrundeliegenden Daten und des Modells. Darüber hinaus kann die Berechnung von 
SHAP-Werten insbesondere bei großen Datensätzen rechenintensiv sein, was praktische Einschränkungen 
mit sich bringt \cite[S. 224]{Molnar_2022}.

Ein Nachteil ist die potenzielle Verzerrung, die durch die Stichprobenabhängigkeit 
der SHAP-Werte entstehen kann. SHAP-Werte basieren auf der Annahme, dass die Daten, auf denen
das Modell trainiert wurde, repräsentativ für die zugrunde liegende Population sind. 
Wenn diese Annahme nicht erfüllt ist, können die SHAP-Werte irreführende Interpretationen liefern.

Zusammenfassend lässt sich sagen, dass SHAP-Werte eine bedeutende Erweiterung der Möglichkeiten
zur Interpretation von linearen Modellen darstellen. Sie bieten tiefergehende Einblicke in die 
Funktionsweise von linearen Modellen und ermöglichen eine präzisere und umfassendere Analyse der Merkmalsrelevanz 
und -interaktionen. Dennoch ist es entscheidend, ihre Limitationen zu verstehen und sie als 
einen Teil eines umfassenden Prozesses der Modellinterpretation und -validierung zu betrachten. 