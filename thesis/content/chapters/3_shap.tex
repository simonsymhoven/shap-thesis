\chapter{Von Shapley-Werten zu SHAP: Brückenschlag zur Modellinterpretation}

Im Rahmen der kooperativen Spieltheorie ermöglichen die Shapley-Werte eine faire Verteilung des kollektiv 
erwirtschafteten Nutzens auf die beteiligten Akteure. Diese Methodik findet eine analoge Anwendung 
in der Welt des maschinellen Lernens, um die Beiträge einzelner Merkmale zur Vorhersageleistung 
eines Modells zu bewerten. Hier wird die Terminologie der Shapley-Werte in den Kontext von Machine Learning 
Modellen übertragen, wobei jedes Merkmal als \glqq{}Spieler\grqq{} betrachtet wird, dessen Beitrag zur 
\glqq{}Auszahlung\grqq{} – der Vorhersage des Modells – evaluiert werden soll. 

\begin{table}[h]
    \caption{Terminologie der originären Shapley-Werte im Kontext des maschinellen Lernens.}
    \footnotesize
    \begin{tabularx}{\textwidth}{XXX}
    \toprule
    Terminologie Konzept & Terminologie Machine Learning & Ausdruck \\
    \midrule
    Spieler & Merkmal Index & $j$ \\
    Anzahl aller Spieler & Anzahl aller Merkmale & $p$ \\
    Große Koalition & Menge aller Merkmale & $\mathcal{N} = \{1, \ldots, p\}$\\
    Koalition & Menge von Merkmalen & $\mathcal{S} \subseteq \mathcal{N}$ \\
    Größe der Koalition & Anzahl der Merkmale in der Koalition $\mathcal{S}$ & $|\mathcal{S}|$\\
    Spieler, die nicht in der Koalition sind & Merkmale, die nicht in der Koalition enthalten sind & $C: C = \mathcal{N} \setminus \mathcal{S}$ \\
    Koalitionsfunktion & Vorhersage für Merkmalswerte in der Koalition $\mathcal{S}$ abzüglich der Vorhersage im Mittel & $v_{f, x^{(i)}}(\mathcal{S}$)\\
    Auszahlung & Vorhersage für eine Beobachtung $x^{(i)}$ abzüglich der Vorhersage im Mittel & $f(x^{(i)}) -  \mathbb{E}(f(X))$\\
    Shapley-Wert & Beitrag des Merkmals $j$ zur Auszahlung des Modells für eine Beobachtung $x^{(i)}$& $\varphi_j^{(i)}(\mathcal{N}, f)$\\
    \bottomrule
    \end{tabularx}
    \label{tab:shapley_terms}
    \normalsize\\
    Quelle: \cite[S. 26]{Molnar_2023}.
\end{table}

Die Koalitionsfunktion $v_{f, x^{(i)}}(\mathcal{S})$ für ein gegebenes Model $f$ und eine Beobachtung $x^{(i)}$ ist definiert als:

\begin{align}
    v_{f, x^{(i)}}(\mathcal{S}) = \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S}} \cup X_{C}) d\mathbb{P}_{X_{C}} - \mathbb{E}(f(X))
\end{align}

Diese Funktion berechnet den erwarteten Wert der Vorhersage des Modells $f$, wenn nur eine Teilmenge $\mathcal{S}$ der 
Merkmale genutzt wird, um die Vorhersage für die spezifische Beobachtung $x^{(i)} \in \mathbb{R}^{p}$ zu treffen. 
Das Integral $\int_{\mathbb{R}}$ repräsentiert die Berechnung dieses erwarteten Wertes über alle möglichen Werte der Merkmale, 
die nicht in $\mathcal{S}$ enthalten sind ($X_C$), gewichtet durch deren Wahrscheinlichkeitsverteilung $\mathbb{P}_{X_{C}}$. 
Die Differenz zum Erwartungswert der Vorhersagen über alle Merkmale $\mathbb{E}(f(X))$ zeigt, 
wie viel die spezifische Menge an Merkmalen $\mathcal{S}$ zur Vorhersage beiträgt \cite[S. 221, S. 27]{Molnar_2022, Molnar_2023}.

Der marginale Beitrag eines Merkmals $j$ zu einer Koalition $\mathcal{S}$ ist dann:

\begin{align}
    v_{f, x^{(i)}}(\mathcal{S} \cup \{j\}) - v_{f, x^{(i)}}(\mathcal{S}) &= \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S} \cup \{j\}} \cup X_{C \setminus \{j\}}) d\mathbb{P}_{X_{C \setminus \{j\}}} - \mathbb{E}(f(X)) \\ \notag
    &\quad - \left( \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S}} \cup X_{C}) d\mathbb{P}_{X_{C}} - \mathbb{E}(f(X)) \right) \\ \notag
    &= \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S} \cup \{j\}} \cup X_{C \setminus \{j\}}) d\mathbb{P}_{X_{C \setminus \{j\}}} \\ \notag
    &\quad - \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S}} \cup X_{C}) d\mathbb{P}_{X_{C}}
\end{align}

Diese Gleichung beschreibt, wie sich der erwartete Wert der Vorhersage ändert, wenn das Merkmal $j$ zu der Menge der Merkmale $\mathcal{S}$ hinzugefügt wird \cite[S. 29]{Molnar_2023}.

Der Beitrag $\varphi_j^{(i)}(\mathcal{N}, f)$ eines Merkmals $j$ für eine Beobachtung $x^{(i)} \in \mathbb{R}^{p}$ für die Vorhersage $f(x^{(i)})$ ist gegeben als:

\begin{align}
    \label{eq:shap-eq}
    \varphi^{(i)}_{j} (\mathcal{N}, f) &= \sum_{\mathcal{S} \subseteq \mathcal{N} \setminus \{j\}} \frac{|\mathcal{S}|! \cdot (p - 1 - |\mathcal{S}|)!}{p!} \\ \notag
    &\quad \cdot \left( \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S} \cup \{j\}} \cup X_{C \setminus \{j\}}) d\mathbb{P}_{X_{C \setminus \{j\}}} -
    \int_{\mathbb{R}} f(x^{(i)}_{\mathcal{S}} \cup X_{C}) d\mathbb{P}_{X_{C}} \right) 
\end{align}

Diese Formel ist die zentrale Berechnung der SHAP-Werte im maschinellen Lernen. 
Sie summiert den gewichteten, marginalen Beitrag des Merkmals $j$ über alle möglichen Kombinationen der anderen Merkmale. 
Die Gewichtung berücksichtigt die Anzahl der Merkmale in der Koalition $\mathcal{S}$ und die Anzahl der verbleibenden Merkmale, 
die noch hinzugefügt werden können. Dies ergibt den durchschnittlichen Beitrag des Merkmals $j$ zur Vorhersage für die 
Beobachtung $x^{(i)}$ \cite[S. 29, 30]{Molnar_2023}.

Die Integration in der SHAP-Formel ist ein zentraler Schritt, um den erwarteten Beitrag jedes Merkmals unter 
Berücksichtigung der gesamten Verteilung der Daten zu ermitteln. 
In diesem Ansatz werden die Merkmale als Zufallsvariablen behandelt, und die Integration erfolgt über 
die Wahrscheinlichkeitsverteilungen dieser Zufallsvariablen. Durch das Berechnen der erwarteten Vorhersagewerte mit 
und ohne des jeweiligen Merkmals, unter Einbeziehung der Verteilung aller anderen Merkmale, 
ermöglicht SHAP eine präzise und umfassende Einschätzung des Einflusses jedes einzelnen Merkmals. 
Dieser Prozess der Marginalisierung, bei dem man über die Wahrscheinlichkeitsverteilungen der Merkmale integriert, 
erlaubt es, den Beitrag eines jeden Merkmals zu isolieren und unabhängig von der spezifischen Zusammensetzung 
der anderen Merkmale zu bewerten. Dies führt zu einer fairen und ganzheitlichen Bewertung der Beiträge aller Merkmale 
zur Vorhersage des Modells \cite[S. 28]{Molnar_2023}.

\section{Berechnung der SHAP-Werte unter Berücksichtigung der zugrundeliegenden Verteilung}
\label{sec:example}

Ein einfaches Beispiel soll helfen, die Anwendung von SHAP-Werten im 
Kontext des maschinellen Lernens zu illustrieren\footnote{In Anlehnung an das Beispiel aus Kapitel 8.5.1 \glqq{}General Idea\grqq{} \cite[S.215f]{Molnar_2022}.}. Betrachtet wird ein fiktiver 
Immobilien-Datensatz mit drei Merkmalen: Größe des Hauses in Quadratmetern ($x_1$), Anzahl der Zimmer ($x_2$) 
und Entfernung zum Stadtzentrum in Kilometern ($x_3$). Es gibt zwei Beobachtungen in diesem Datensatz:

\begin{table}[h]
    \caption{Merkmale von Beobachtungen in einem Immobilien-Datensatz.}
    \footnotesize
    \begin{tabularx}{\textwidth}{Xrrr}
    \toprule
     & $x_1$: Größe (in $m^2$) &  $x_2$: Anzahl Zimmer &  $x_3$: Entfernung zum Zentrum (in km) \\
    \midrule
    $x^{(1)}$ & 100 & 3 & 5 \\
    $x^{(2)}$ & 150 & 4 & 10 \\
    \bottomrule
    \end{tabularx}
    \label{tab:example}
    \normalsize\\
    Quelle: Eigene Darstellung.
\end{table}

Angenommen das Modell $f(x^{(i)})$ prognostiziert den Preis eines Hauses in Euro als eine lineare Kombination der Merkmale:

\begin{equation}
    f(x^{(i)}) = 5x_1^{(i)} + 20x_2^{(i)} - 2x_3^{(i)}.
\end{equation}

Die Vorhersagen für die beiden Beobachtungen lauten dann:

\begin{align}
    \label{eq:fx1}
    f(x^{(1)}) &= 5x_1^{(1)} + 20x_2^{(1)} - 2x_3^{(1)} \\ \notag
        &= 5 \cdot 100 + 20 \cdot 3 - 2 \cdot 5 \\ \notag
        &= 550\,\text{\euro} 
\end{align}

und 

\begin{align}
    f(x^{(2)}) &= 5x_1^{(2)} + 20x_2^{(2)} - 2x_3^{(2)} \\ \notag
        &= 5 \cdot 150 + 20 \cdot 4 - 2 \cdot 10 \\ \notag
        &= 810\,\text{\euro}. 
\end{align}

Die erwartete Auszahlung des Modells $\mathbb{E}(f(X))$ wird berechnet als:
\begin{align}
    \label{eq:efx}
    \mathbb{E}(f(X)) &= 5 \cdot \mathbb{E}(X_1) + 20 \cdot \mathbb{E}(X_2) - 2 \cdot \mathbb{E}(X_3) \\ \notag
                     &= 5 \cdot 125 + 20 \cdot 3,5 - 2 \cdot 7,5 \\ \notag
                     &= 680 \,\text{\euro},
\end{align}

mit 

\begin{align}
    \label{eq:e}
    \mathbb{E}(X_j) = \frac{1}{n} \sum_{i=1}^{n} x_j^{(i)}.
\end{align}     

Sei $\mathcal{N} = \{1, 2, 3\}$ die Menge aller Merkmale und die Beobachtung $x^{(1)} = [100, 3, 5]$. 
Der SHAP-Wert für jedes Merkmal $j \in \mathcal{N}$ wird unter Berücksichtigung der Verteilung der 
Daten und der Formel \ref{eq:shap-eq} berechnet:

\begin{align}
    \label{eq:shap-formular}
    \varphi^{(1)}_{j} (\mathcal{N}, f) &= \sum_{\mathcal{S} \subseteq \mathcal{N} \setminus \{j\}} \frac{|\mathcal{S}|! \cdot (p - 1 - |\mathcal{S}|)!}{p!} \\ \notag
    &\quad \cdot \left( \int_{\mathbb{R}} f(x^{(1)}_{\mathcal{S} \cup \{j\}} \cup X_{C \setminus \{j\}}) d\mathbb{P}_{X_{C \setminus \{j\}}} -
    \int_{\mathbb{R}} f(x^{(1)}_{\mathcal{S}} \cup X_{C}) d\mathbb{P}_{X_{C}} \right) 
\end{align}

wobei $p = |\mathcal{N}| = 3$ die Anzahl der Merkmale ist und $X_C$ die Menge der Merkmale 
außerhalb der Koalition $\mathcal{S}$ repräsentiert. Die Integrale repräsentieren die erwartete 
Vorhersage des Modells über die Verteilung der nicht in der Koalition enthaltenen Merkmale.

In linearen Modellen, unter der Prämisse, dass die Merkmale unabhängig voneinander und gleichverteilt sind, 
ist es möglich, die Berechnung der SHAP-Werte zu vereinfachen. Anstelle der komplexen Integration 
über die Verteilungen aller Merkmale, kann der Fokus auf die Unterschiede in den Modellvorhersagen gelegt werden, 
die sich aus dem Hinzufügen oder Entfernen einzelner Merkmale ergeben. 
Hierbei wird anstelle der spezifischen Werte der nicht in der betrachteten Koalition enthaltenen Merkmale 
Erwartungswerte herangezogen. Diese Vereinfachung ermöglicht es, den Einfluss jedes Merkmals auf 
die Modellvorhersage auf eine direktere und rechnerisch weniger aufwendige Weise zu erfassen.
Diese Vereinfachung ist für lineare Modelle angemessen, da die Auswirkungen jedes Merkmals 
auf die Vorhersage des Modells additiv und unabhängig sind. Bei komplexeren, 
nichtlinearen Modellen ist eine detailliertere Berechnung erforderlich, 
die oft auf numerischen Methoden oder Annäherungen basiert, mehr dazu in Kapitel \ref{sec:estimators}.

Der Beitrag durch das Hinzufügen des Merkmals $x_1$ zur bestehenden Koalition $\mathcal{S} = \{x_2\}$ wird
nach Formel \ref{eq:shap-formular} berechnet als:

\begin{align}
    \varphi^{(1)}_{1}(\{x_2\}, f) &= \frac{1! \cdot (3 - 1 - 1)!}{3!} \\ \notag
        &\quad \cdot \int f(x_1, x_2 , X_3) d\mathbb{P}(X_3) - \int f(X_1, x_2, X_3) d\mathbb{P}(X_1, X_3)
\end{align}

Da \( X_1 \) und \( X_3 \) unabhängig und gleichmäßig verteilt sind, können \( X_2 \) und \( X_3 \) durch ihre Erwartungswerte (Gleichung \ref{eq:e}) ersetzt werden:

\begin{align}
    \varphi^{(1)}_{1}(\{x_2\}, f) &= \frac{1}{6} \Big(f(x_1, x_2, \mathbb{E}(X_3)) - f(\mathbb{E}(X_1), x_2, \mathbb{E}(X_3))\Big) \\ \notag
        &= \frac{1}{6} \Big( f(100, 3, 7.5) - f(125, 3, 7.5) \Big) \\ \notag
        &= \frac{1}{6} \Big( (5 \cdot 100 + 20 \cdot 3 - 2 \cdot 7,5) - (5 \cdot 125 + 20 \cdot 3 - 2 \cdot 7,5) \Big) \\ \notag
        &= \frac{1}{6} (545 - 670) \\ \notag
        &= \frac{1}{6} (-125)
\end{align}
 
Die in Tabelle \ref{tab:shapley_marginal_features} dargestellten Kombinationen illustrieren die marginalen Beiträge und SHAP-Werte 
für jedes Merkmal in jeder möglichen Koalition von Merkmalen, bezogen auf die Beobachtung $x^{(1)}$. 

\begin{table}[h]
    \caption{Marginalbeiträge der einzelnen Merkmale zu den möglichen Koalitionen für die Beobachtung $x^{(1)}$.}
    \footnotesize
    \begin{tabularx}{\textwidth}{XXrrrrr}
    \toprule
    $x_{j}$ & $\mathcal{S}$ & $v_{f, x^{(1)}}(\mathcal{S})$ & $v_{f, x^{(1)}}(\mathcal{S} \cup \{j\})$ & $v_{f, x^{(1)}}(\mathcal{S} \cup \{j\}) - v_{f, x^{(1)}}(\mathcal{S})$ & Gewicht & $\varphi_{j}^{(1)}(\mathcal{S}, f)$\\
    \midrule
    $x_1$ & $\emptyset$ & 680 & 555 & -125 & $\frac{1}{3}$ & -41,67 \\
    $x_1$ & $\{x_2\}$ & 670 & 545 & -125 & $\frac{1}{6}$ & -20.83 \\
    $x_1$ & $\{x_3\}$ & 685 & 560 & -125 & $\frac{1}{6}$ & -20.83 \\
    $x_1$ & $\{x_2, x_3\}$ & 675 & 550 & -125 & $\frac{1}{3}$ & -41,67 \\
    $x_2$ & $\emptyset$ & 680 & 670 & -10 & $\frac{1}{3}$ & -3,33 \\
    $x_2$ & $\{x_1\}$ & 555 & 545 & -10 & $\frac{1}{6}$ & -1,67 \\
    $x_2$ & $\{x_3\}$ & 685 & 675 & -10 & $\frac{1}{6}$ & -1,67 \\
    $x_2$ & $\{x_1, x_3\}$ & 560 & 550 & -10 & $\frac{1}{3}$ & -3,33 \\
    $x_3$ & $\emptyset$ & 680 & 685 & 5 & $\frac{1}{3}$ & 1,67 \\
    $x_3$ & $\{x_1\}$ & 555 & 560 & 5 & $\frac{1}{6}$ & 0,83 \\
    $x_3$ & $\{x_2\}$ & 670 & 675 & 5 & $\frac{1}{6}$ & 0,83 \\
    $x_3$ & $\{x_1, x_2\}$ & 545 & 550 & 5 & $\frac{1}{3}$ & 1,67 \\
    \bottomrule
    \end{tabularx}
    \label{tab:shapley_marginal_features_x1}
    \normalsize\\
    Quelle: Eigene Darstellung.
\end{table}

Diese Analyse ist ebenso auf die Beobachtung $x^{(2)}$ anwendbar und erfordert eine analoge Vorgehensweise:

\begin{table}[h]
    \caption{Marginalbeiträge der einzelnen Merkmale zu den möglichen Koalitionen für die Beobachtung $x^{(2)}$.}
    \footnotesize
    \begin{tabularx}{\textwidth}{XXrrrrr}
    \toprule
    $x_{j}$ & $\mathcal{S}$ & $v_{f, x^{(2)}}(\mathcal{S})$ & $v_{f, x^{(2)}}(\mathcal{S} \cup \{j\})$ & $v_{f, x^{(2)}}(\mathcal{S} \cup \{j\}) - v_{f, x^{(2)}}(\mathcal{S})$ & Gewicht & $\varphi_{j}^{(2)}(\mathcal{S}, f)$\\
    \midrule
    $x_1$ & $\emptyset$ & 680 & 805 & 125 & $\frac{1}{3}$ & 41,67 \\
    $x_1$ & $\{x_2\}$ & 690 & 815 & 125 & $\frac{1}{6}$ & 20.83 \\
    $x_1$ & $\{x_3\}$ & 675 & 800 & 125 & $\frac{1}{6}$ & 20.83 \\
    $x_1$ & $\{x_2, x_3\}$ & 685 & 810 & 125 & $\frac{1}{3}$ & 41,67 \\
    $x_2$ & $\emptyset$ & 680 & 690 & 10 & $\frac{1}{3}$ & 3,33 \\
    $x_2$ & $\{x_1\}$ & 805 & 815 & 10 & $\frac{1}{6}$ & 1,67 \\
    $x_2$ & $\{x_3\}$ & 675 & 685 & 10 & $\frac{1}{6}$ & 1,67 \\
    $x_2$ & $\{x_1, x_3\}$ & 800 & 810 & 10 & $\frac{1}{3}$ & 3,33 \\
    $x_3$ & $\emptyset$ & 680 & 675 & -5 & $\frac{1}{3}$ & -1,67 \\
    $x_3$ & $\{x_1\}$ & 805 & 800 & -5 & $\frac{1}{6}$ & -0,83 \\
    $x_3$ & $\{x_2\}$ & 690 & 685 & -5 & $\frac{1}{6}$ & -0,83 \\
    $x_3$ & $\{x_1, x_2\}$ & 815 & 810 & -5 & $\frac{1}{3}$ & -1,67 \\
    \bottomrule
    \end{tabularx}
    \label{tab:shapley_marginal_features_x2}
    \normalsize\\
    Quelle: Eigene Darstellung.
\end{table}

Die in den Tabellen \ref{tab:shapley_marginal_features_x1} und \ref{tab:shapley_marginal_features_x2} 
dargestellten SHAP-Werte für die Beobachtungen \( x^{(1)} \) und \( x^{(2)} \) zeigen eine interessante Symmetrie. 
Für jedes Merkmal entspricht der SHAP-Wert für \( x^{(2)} \) genau dem negativen Wert für \( x^{(1)} \). 
Die beobachtete Inversion der SHAP-Werte zwischen den Beobachtungen \( x^{(1)} \) und \( x^{(2)} \) 
lässt sich durch die zentrale Rolle des Erwartungswerts des Modells erklären. 
Das Modell prognostiziert im Mittel einen Immobilienpreis von 680 \euro. In einem Szenario, in dem nur zwei 
Beobachtungen vorhanden sind, spiegeln die Beobachtungen \( x^{(1)} \) und \( x^{(2)} \) entgegengesetzte 
Abweichungen vom Erwartungswert wider. Die SHAP-Werte, die den Beitrag jedes Features zur Abweichung 
der Vorhersage vom Mittelwert messen, zeigen daher für \( x^{(1)} \) und \( x^{(2)} \) genau entgegengesetzte Werte. 
Dieses Phänomen resultiert aus der Tatsache, dass die Merkmalsbeiträge in Bezug auf den Erwartungswert 
berechnet werden und unsere beispielhaften Beobachtungen symmetrisch um diesen Mittelwert verteilt sind. 
Folglich heben sich ihre Beiträge im Kontext unseres linearen Modells exakt auf, was die Konsistenz und 
Zuverlässigkeit der SHAP-Wert-Berechnung unterstreicht.


\begin{figure}[H]
    \caption{Beitrag der Merkmale $x_{j \in \{1, 2, 3\}}$ zur Modellvorhersage $f(x^{(1)})$.}
    \includegraphics[width=1\textwidth]{../scripts/images/model-output-x1.png}
    Quelle: Eigene Darstellung, \ref{charts}.
    \label{pic:model-fx1}
\end{figure}

Das Modell $f(x^{(i)})$
prognostiziert im Mittel einen Immobilienpreis von 680 \euro{}. Im Vergleich zur
Verteilung des jeweiligen Merkmals, reduziert die Größe der 
Wohnung ($x_1^{(1)}$) und die Anzahl der Zimmer ($x_2^{(1)}$) die Prognose 
des Preises für die Immobilie $x^{(1)}$ um insgesamt 135 \euro{}, während die Entfernung zum Stadtzentrum
($x_3^{(1)}$) den Preis der Wohnung um 5 \euro{} erhöht, wie in Abbildung 
\ref{pic:model-fx1} veranschaulicht. Abbildung \ref{pic:model-fx2} visualisiert die SHAP-Werte für die Immobilie $x^{(2)}$:

\begin{figure}[H]
    \caption{Beitrag der Merkmale $x_{j \in \{1, 2, 3\}}$ zur Modellvorhersage $f(x^{(2)})$.}
    \includegraphics[width=1\textwidth]{../scripts/images/model-output-x2.png}
    Quelle: Eigene Darstellung, \ref{charts}.
    \label{pic:model-fx2}
\end{figure}


\section{Axiome}

Die in Tabellen \ref{tab:shapley_marginal_features_x1} und \ref{tab:shapley_marginal_features_x2} präsentierten Ergebnisse bieten eine Grundlage, 
um die Konformität der SHAP-Werte mit den etablierten Axiomen der Shapley-Werte, wie sie im 
Kapitel \ref{sec:axiome-shapley} diskutiert wurden, zu beurteilen. Die Axiome der SHAP-Werte stellen 
eine adaptierte und kontextualisierte Anwendung dieser Prinzipien auf die Interpretation von 
Modellvorhersagen dar \cite{NIPS2017_8a20a862}.


\paragraph{Effizienz}

Das Effizienzaxiom besagt, dass die Summe der SHAP-Werte aller Features für eine gegebene Beobachtung $x^{(i)}$ 
gleich der Differenz zwischen der Modellvorhersage für diese Beobachtung $f(x^{(i)})$ 
und der durchschnittlichen Modellvorhersage $\mathbb{E}(f(X))$ sein muss:

\begin{align}
    \sum_{j=1}^{p}\varphi_j^{(i)}(\mathcal{N}, f) = f(x^{(i)}) - \mathbb{E}(f(X)),
\end{align}

\cite[S. 221]{Molnar_2022}. Für die Beobachtung $x^{(1)}$ aus Kapitel \ref{sec:example} und den Berechnungen 
für $f(x^{(1)})$ (Gleichung \ref{eq:fx1}), sowie $\mathbb{E}(f(X))$ (Gleichung \ref{eq:efx}) ergibt sich:

\begin{align}
    \sum_{j=1}^{3}\varphi_j^{(1)}(\mathcal{N}, f) &=  -130 \\ \notag
    f(x^{(1)}) - \mathbb{E}(f(X)) &= 550 - 680 = -130,   
\end{align}

womit das Effizienzaxiom erfüllt ist. Die Differenz der Vohersage 
einer konkreten Beobachtung zur durchschnittlichen 
Modellvorhersage wird auf alle Merkmale verteilt.

\paragraph{Symmetrie}

Das Symmetrieaxiom fordert, dass zwei Merkmale $i$ und $j$, die 
in jeder Koalition denselben Beitrag leisten, auch denselben SHAP-Wert 
erhalten müssen. In dem hier betrachteten Fall der Immobilienpreisprognose 
würde dies bedeuten, dass wenn zwei Merkmale, beispielsweise die Größe einer 
Wohnung und die Anzahl der Zimmer, immer den gleichen Einfluss auf den Preis hätten, 
unabhängig von der Kombination anderer Merkmale, ihre SHAP-Werte identisch 
sein müssen:

\begin{equation}
    v(\mathcal{S} \cup \{i\}) = v(\mathcal{S} \cup \{j\}), \; \forall\, \mathcal{S} \subseteq \mathcal{N} \setminus \{i, j\} \Rightarrow \varphi_i (\mathcal{N}, v) = \varphi_j (\mathcal{N}, v),
\end{equation}

\cite[S. 221]{Molnar_2022}. Dies wird durch die Tabellen \ref{tab:shapley_marginal_features_x1} und \ref{tab:shapley_marginal_features_x2} 
nicht illustriert, da jedes Merkmal einen unterschiedlichen Beitrag liefert, 
was die Anwendung dieses Axioms in diesem speziellen Fall ausschließt.

\paragraph{Null-Spieler-Eigenschaft (Dummy-Spieler-Eigenschaft)}

Ein Merkmal $i$, das keinen Einfluss auf die Modellvorhersage hat, erhält gemäß der 
Null-Spieler-Eigenschaft einen SHAP-Wert von Null. 
Im Kontext des Beispiels würde ein Merkmal, das keine Veränderung in der Vorhersage 
bewirkt, unabhängig von den anderen Merkmalen, einen SHAP-Wert von Null erhalten:

\begin{equation}
    v(\mathcal{S} \cup \{i\}) =  v(\mathcal{S}), \; \forall\, \mathcal{S} \subseteq \mathcal{N} \setminus \{i\} \Rightarrow \varphi_i (\mathcal{N}, v) = 0,
\end{equation}

\cite[S. 222]{Molnar_2022}. In der fiktiven Datenlage der Tabellen \ref{tab:shapley_marginal_features_x1} und \ref{tab:shapley_marginal_features_x2} hat jedes Merkmal 
einen gewissen Einfluss, sodass die Null-Spieler-Eigenschaft hier nicht beobachtet werden kann.

\paragraph{Additivität}

Das Additivitätsaxiom ist ein zentrales Konzept, das die Konsistenz von Shapley-Werten 
über die Zusammensetzung von Spielen hinweg beschreibt. Es garantiert, 
dass für zwei separate Spiele oder Modelle \(v\) und \(w\), die Summe der SHAP-Werte eines 
Merkmals über beide Spiele seinem SHAP-Wert im kombinierten Spiel entspricht:

\begin{equation}
    \varphi_i(\mathcal{N}, v + w) = \varphi_i (\mathcal{N}, v) + \varphi_i (\mathcal{N}, w).
\end{equation}

Im Rahmen von Machine Learning-Modellen, insbesondere bei Ensemble Modellen wie dem Random Forest, 
ist die Additivität besonders relevant. Ein Random Forest-Modell ist im Wesentlichen eine Sammlung 
von Entscheidungsbäumen, die jeweils als unabhängige Modelle angesehen werden können. 
Diese Bäume arbeiten zusammen, um eine gemeinsame Vorhersage zu treffen, indem sie ihre 
individuellen Vorhersagen durchschnittlich zusammenführen. Gemäß dem Additivitätsaxiom können die SHAP-Werte, 
die aus den einzelnen Entscheidungsbäumen berechnet werden, als additive Beiträge betrachten, 
die zusammen den Gesamteinfluss eines Features auf die Vorhersage des gesamten Random Forest-Modells ausmachen \cite[S. 32]{Molnar_2023}.


\chapter{Schätzung von SHAP-Werten}
\label{sec:estimators}

Die Berechnung von SHAP-Werten stellt in der Praxis eine erhebliche Herausforderung dar, 
insbesondere bei komplexen Modellen Random Forests oder tiefen neuronalen Netzwerken. 
Während das Beispiel mit Immobilienpreisen noch eine direkte Ermittlung aller möglichen Kombinationen 
von Merkmalen und deren Beiträgen ermöglicht, ist dies bei umfangreichen Datensätzen und Modellen 
mit einer hohen Anzahl von Merkmalen kaum praktikabel. Die rechnerische Komplexität steigt exponentiell 
mit der Anzahl der Merkmale, wodurch eine vollständige Berechnung aller möglichen Merkmalskombinationen schnell unhandlich wird.

In dem Immobilienbeispiel ist es noch möglich, die SHAP-Werte direkt aus den Modellgleichungen abzuleiten, 
da die Beziehungen zwischen den Merkmalen und dem Zielwert klar definiert und leicht zugänglich sind. 
Dies spiegelt sich in der integralen Form der SHAP-Wert-Formel wider, die eine Kenntnis der Verteilung der 
Eingabedaten voraussetzt. Um das Integral zu berechnen, ist es notwendig, die Wahrscheinlichkeitsverteilung 
über die Merkmale zu kennen, was in realen Szenarien oft nicht der trivial ist.

In diesem Kapitel konfrontieren wir uns mit der Fragestellung, wie SHAP-Werte in praktischen, 
weniger transparenten Situationen geschätzt werden können. Wir diskutieren Ansätze, 
die eine Näherung der wahren SHAP-Werte erlauben, ohne auf die vollständige Berechnung 
aller Feature-Kombinationen zurückgreifen zu müssen. Besondere Aufmerksamkeit widmen wir dem 
linearen Estimator, der auf der Annahme beruht, dass das Modellverhalten in der Nähe der untersuchten Beobachtung 
durch ein lineares Modell angenähert werden kann. Diese Annäherung ermöglicht es, die SHAP-Werte 
effizient zu schätzen, ohne dabei die rechnerische Last einer vollständigen kombinatorischen Analyse 
tragen zu müssen. Die daraus resultierenden Schätzungen bieten einen praktikablen Kompromiss zwischen Genauigkeit 
und Berechnungsaufwand und erlauben es, die Beiträge der einzelnen Features zur Modellvorhersage in einer für 
den Anwender interpretierbaren Weise zu quantifizieren.
